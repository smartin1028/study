# Python + ELK를 활용한 로그 분석 시스템 예제

ELK 스택(Elasticsearch, Logstash, Kibana)과 Python을 함께 사용하여 로그 분석 시스템을 구축하는 방법을 설명드리겠습니다.

## 1. 시스템 아키텍처 개요

```
Python 애플리케이션 → Logstash → Elasticsearch → Kibana
```

## 2. 필요한 구성 요소 설치

### ELK 스택 설치 (도커 사용 추천)
```bash
# Elasticsearch
docker pull docker.elastic.co/elasticsearch/elasticsearch:8.7.0
docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:8.7.0

# Logstash
docker pull docker.elastic.co/logstash/logstash:8.7.0

# Kibana
docker pull docker.elastic.co/kibana/kibana:8.7.0
docker run -p 5601:5601 --name kibana --link elasticsearch:elasticsearch docker.elastic.co/kibana/kibana:8.7.0
```

## 3. Python에서 로그 생성 및 전송 예제

### 예제 1: Python 로깅 모듈을 사용하여 Logstash로 전송

```python
import logging
from logstash_async.handler import AsynchronousLogstashHandler

# 로거 설정
def setup_logging():
    host = 'localhost'
    port = 5000  # Logstash TCP 입력 포트
    
    logger = logging.getLogger('python-logstash-logger')
    logger.setLevel(logging.INFO)
    
    # Logstash 핸들러 추가
    logstash_handler = AsynchronousLogstashHandler(
        host, port, database_path='logstash.db')
    logger.addHandler(logstash_handler)
    
    return logger

# 로그 생성 예제
def generate_logs(logger):
    import random
    import time
    
    log_levels = ['INFO', 'WARNING', 'ERROR']
    actions = ['login', 'search', 'purchase', 'logout']
    users = ['user1', 'user2', 'user3', 'user4', 'user5']
    
    for i in range(100):
        level = random.choice(log_levels)
        action = random.choice(actions)
        user = random.choice(users)
        duration = random.uniform(0.1, 5.0)
        
        extra = {
            'user': user,
            'action': action,
            'duration': duration,
            'tags': ['python', 'webapp']
        }
        
        if level == 'INFO':
            logger.info(f"User {user} performed {action} in {duration:.2f}s", extra=extra)
        elif level == 'WARNING':
            logger.warning(f"Slow action detected: {action} took {duration:.2f}s", extra=extra)
        else:
            logger.error(f"Error during {action} by {user}", extra=extra)
        
        time.sleep(random.uniform(0.1, 1.0))

if __name__ == '__main__':
    logger = setup_logging()
    generate_logs(logger)
```

### 예제 2: requests를 사용하여 Elasticsearch에 직접 전송

```python
import requests
import json
import random
import time
from datetime import datetime

ELASTICSEARCH_URL = "http://localhost:9200"
INDEX_NAME = "python-logs"

def create_index():
    """Elasticsearch 인덱스 생성"""
    mapping = {
        "mappings": {
            "properties": {
                "timestamp": {"type": "date"},
                "level": {"type": "keyword"},
                "message": {"type": "text"},
                "user": {"type": "keyword"},
                "action": {"type": "keyword"},
                "duration": {"type": "float"},
                "source": {"type": "keyword"}
            }
        }
    }
    
    response = requests.put(f"{ELASTICSEARCH_URL}/{INDEX_NAME}", json=mapping)
    print(f"Index creation response: {response.status_code} - {response.text}")

def send_log_to_elasticsearch(log_data):
    """Elasticsearch에 로그 전송"""
    url = f"{ELASTICSEARCH_URL}/{INDEX_NAME}/_doc"
    headers = {"Content-Type": "application/json"}
    
    response = requests.post(url, data=json.dumps(log_data), headers=headers)
    return response.status_code == 201

def generate_and_send_logs():
    """랜덤 로그 생성 및 전송"""
    levels = ['INFO', 'WARNING', 'ERROR']
    actions = ['login', 'search', 'purchase', 'logout', 'view']
    users = ['user1', 'user2', 'user3', 'user4', 'user5']
    
    for i in range(50):
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": random.choice(levels),
            "message": f"Log entry {i}",
            "user": random.choice(users),
            "action": random.choice(actions),
            "duration": random.uniform(0.1, 3.0),
            "source": "python-script"
        }
        
        if send_log_to_elasticsearch(log_entry):
            print(f"Sent log: {log_entry}")
        else:
            print(f"Failed to send log: {log_entry}")
        
        time.sleep(random.uniform(0.5, 2.0))

if __name__ == '__main__':
    create_index()
    generate_and_send_logs()
```

## 4. Logstash 구성 파일 예제

`logstash.conf` 파일:

```conf
input {
  tcp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # 필요한 경우 추가 필터링
  mutate {
    convert => {
      "duration" => "float"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "python-logs-%{+YYYY.MM.dd}"
    user => "elastic"
    password => "your_password"
  }
  
  # 디버깅용 stdout 출력
  stdout {
    codec => rubydebug
  }
}
```

## 5. Kibana에서 데이터 시각화

1. Kibana에 접속 (http://localhost:5601)
2. "Stack Management" → "Index Patterns"에서 "python-logs-*" 인덱스 패턴 생성
3. "Discover" 탭에서 로그 데이터 확인
4. "Visualize"에서 다양한 차트 생성 가능

### 예제 시각화:
- 사용자별 액션 수 (파이 차트)
- 시간별 로그 레벨 분포 (히스토그램)
- 액션별 평균 지속 시간 (바 차트)

## 6. 고급 활용 팁

1. **Python 로그 필터링**: 로그를 전송하기 전에 Python에서 필터링
   ```python
   class ImportantLogFilter(logging.Filter):
       def filter(self, record):
           return record.levelno >= logging.WARNING
   
   logger.addFilter(ImportantLogFilter())
   ```

2. **대용량 처리**: Python에서 bulk API 사용
   ```python
   def send_bulk_logs(logs):
       bulk_data = []
       for log in logs:
           bulk_data.append(json.dumps({"index": {}}))
           bulk_data.append(json.dumps(log))
       
       response = requests.post(
           f"{ELASTICSEARCH_URL}/{INDEX_NAME}/_bulk",
           data="\n".join(bulk_data) + "\n",
           headers={"Content-Type": "application/x-ndjson"}
       )
       return response.json()
   ```

3. **보안 설정**: Elasticsearch에 인증 추가
   ```python
   from elasticsearch import Elasticsearch
   
   es = Elasticsearch(
       ['localhost'],
       http_auth=('elastic', 'your_password'),
       scheme="http",
       port=9200,
   )
   ```

이 예제를 기반으로 실제 시스템에 맞게 조정하여 사용하시면 됩니다. 초기에는 간단한 구성으로 시작하고 점차 필요한 기능을 추가해 나가는 것이 좋습니다.