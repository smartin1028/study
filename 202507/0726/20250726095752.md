# Python으로 로그 파일의 메시지 시작/종료 위치 구분하기

로그 파일에서 특정 포맷을 기준으로 실제 메시지의 시작과 종료 위치를 구분하는 방법을 설명드리겠습니다. 일반적인 접근 방식과 Python 구현 예제를 제공합니다.

## 일반적인 접근 방법

1. **로그 포맷 분석**: 로그 메시지가 어떤 패턴으로 시작하고 끝나는지 확인
2. **정규 표현식 사용**: 메시지 시작/종료를 식별할 수 있는 정규식 패턴 작성
3. **파일 처리**: 로그 파일을 읽어가며 패턴 매칭 수행
4. **위치 기록**: 매칭되는 위치(바이트 오프셋 또는 라인 번호) 저장

## Python 구현 예제

### 예제 1: 정규식을 이용한 메시지 구분

```python
import re

def find_log_messages(log_file_path):
    # 로그 메시지 시작 패턴 (예: 타임스탬프로 시작하는 경우)
    start_pattern = re.compile(r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}')
    messages = []
    current_message = []
    start_pos = 0
    
    with open(log_file_path, 'r') as file:
        for line_num, line in enumerate(file, 1):
            if start_pattern.match(line):
                if current_message:  # 이전 메시지 저장
                    messages.append({
                        'start_line': start_pos,
                        'end_line': line_num - 1,
                        'content': ''.join(current_message)
                    })
                    current_message = []
                start_pos = line_num  # 새 메시지 시작 위치
            current_message.append(line)
        
        # 마지막 메시지 추가
        if current_message:
            messages.append({
                'start_line': start_pos,
                'end_line': line_num,
                'content': ''.join(current_message)
            })
    
    return messages

# 사용 예시
log_messages = find_log_messages('app.log')
for msg in log_messages:
    print(f"Message from line {msg['start_line']} to {msg['end_line']}")
    print(msg['content'][:100] + "...")  # 내용 일부만 출력
```

### 예제 2: 바이트 오프셋 기반 위치 찾기

```python
import re

def find_log_positions(log_file_path):
    pattern = re.compile(r'^\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\]')  # 예시 패턴
    positions = []
    current_start = 0
    prev_end = 0
    
    with open(log_file_path, 'rb') as file:
        buffer = b''
        while True:
            chunk = file.read(4096)  # 청크 단위로 읽기
            if not chunk:
                break
                
            buffer += chunk
            matches = list(pattern.finditer(buffer.decode('utf-8', errors='ignore')))
            
            for i, match in enumerate(matches):
                if i == 0 and not positions:  # 첫 메시지
                    current_start = match.start()
                else:
                    # 이전 메시지의 끝 위치는 현재 메시지 시작 직전
                    positions.append((current_start, match.start() - 1))
                    current_start = match.start()
            
            if matches:
                buffer = buffer[matches[-1].start():]  # 처리된 부분 제거
    
    # 마지막 메시지 추가
    if current_start < file.tell():
        positions.append((current_start, file.tell() - 1))
    
    return positions

# 사용 예시
message_positions = find_log_positions('server.log')
for start, end in message_positions:
    print(f"Message position: {start} byte to {end} byte")
```

## 고급 기법

### 멀티라인 로그 메시지 처리

```python
def parse_multiline_logs(log_file_path):
    start_pattern = re.compile(r'^\[ERROR\]|^\[INFO\]|^\[WARNING\]')  # 로그 레벨로 시작
    messages = []
    current_msg = None
    
    with open(log_file_path, 'r') as f:
        for line_num, line in enumerate(f, 1):
            if start_pattern.match(line):
                if current_msg is not None:
                    messages.append(current_msg)
                current_msg = {
                    'start': line_num,
                    'end': line_num,
                    'lines': [line.strip()]
                }
            else:
                if current_msg is not None:
                    current_msg['lines'].append(line.strip())
                    current_msg['end'] = line_num
    
    if current_msg is not None:
        messages.append(current_msg)
    
    return messages
```

### 로그 포맷에 따른 유연한 처리

```python
from datetime import datetime

def detect_log_format(line):
    # 다양한 로그 포맷을 자동으로 감지
    patterns = [
        (r'^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}', 'timestamp'),
        (r'^\[[\w-]+\]', 'bracketed'),
        (r'^\w{3} \d{1,2}, \d{4}', 'month_date_year'),
    ]
    
    for pattern, format_type in patterns:
        if re.match(pattern, line):
            return format_type
    return 'unknown'

def smart_log_parser(log_file_path):
    messages = []
    current = {'start': 1, 'lines': []}
    
    with open(log_file_path, 'r') as f:
        for line_num, line in enumerate(f, 1):
            format_type = detect_log_format(line)
            
            if format_type != 'unknown' and current['lines']:
                current['end'] = line_num - 1
                messages.append(current)
                current = {'start': line_num, 'lines': []}
            
            current['lines'].append(line.strip())
        
        if current['lines']:
            current['end'] = line_num
            messages.append(current)
    
    return messages
```

## 성능 고려사항

1. **대용량 파일 처리**: 파일을 한 번에 메모리에 로드하지 않고 청크 단위로 처리
2. **효율적인 정규식**: 너무 복잡한 정규식은 성능 저하를 일으킬 수 있음
3. **병렬 처리**: 매우 큰 파일의 경우 multiprocessing 모듈을 사용하여 병렬 처리 가능

이러한 방법들을 조합하면 다양한 형식의 로그 파일에서 메시지의 정확한 시작과 종료 위치를 식별할 수 있습니다.