# 로그 시간 데이터 정규식 및 XML 정보 추출 방법

로그 파일에서 시간 데이터를 정규식으로 찾고 XML 정보를 추출하여 판다스 데이터프레임으로 변환하는 방법을 설명드리겠습니다.

## 문제 분석 요구사항
1. 로그에서 시간 데이터를 정규식으로 찾기
2. 시작과 끝을 구분하여 XML 정보 추출
3. XML이 시작과 중간 사이에 있는 경우만 추출
4. 추출한 XML 정보는 모두 저장하여 판다스 데이터프레임 생성
5. XML 시작 앞 데이터는 별도로 저장

## 구현 코드 예시

```python
import re
import pandas as pd
from bs4 import BeautifulSoup
from io import StringIO

def parse_log_file(log_file_path):
    # 시간 패턴 정규식 (예시: "2023-08-01 12:34:56")
    time_pattern = r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}'
    
    # XML 시작/종료 태그 패턴
    xml_start_pattern = r'<[^/][^>]*>'
    xml_end_pattern = r'</[^>]*>'
    
    results = []
    pre_xml_data = []
    
    with open(log_file_path, 'r', encoding='utf-8') as file:
        current_block = []
        in_xml = False
        xml_content = []
        pre_content = []
        
        for line in file:
            # 시간 데이터 찾기
            time_match = re.search(time_pattern, line)
            timestamp = time_match.group() if time_match else None
            
            # XML 시작 태그 확인
            if re.search(xml_start_pattern, line) and not in_xml:
                in_xml = True
                pre_content = current_block.copy()  # XML 시작 전 데이터 저장
                current_block = [line]
                xml_start_pos = line.find('<')
                xml_content = [line[xml_start_pos:]] if xml_start_pos >= 0 else [line]
            elif in_xml:
                # XML 내용 계속 추가
                current_block.append(line)
                xml_content.append(line)
                
                # XML 종료 태그 확인
                if re.search(xml_end_pattern, line):
                    in_xml = False
                    full_xml = ''.join(xml_content)
                    
                    try:
                        # XML 파싱 시도
                        soup = BeautifulSoup(full_xml, 'xml')
                        if soup.find():
                            # 유효한 XML인 경우 결과에 추가
                            xml_dict = {'timestamp': timestamp}
                            
                            # 모든 XML 태그와 내용을 딕셔너리에 추가
                            for tag in soup.find_all():
                                xml_dict[tag.name] = tag.get_text()
                            
                            # 원본 XML도 저장
                            xml_dict['raw_xml'] = full_xml
                            xml_dict['pre_xml_data'] = '\n'.join(pre_content)
                            
                            results.append(xml_dict)
                            pre_xml_data.append('\n'.join(pre_content))
                    except:
                        # XML 파싱 실패 시 무시
                        pass
                    
                    current_block = []
            else:
                current_block.append(line)
    
    # 결과를 pandas DataFrame으로 변환
    df = pd.DataFrame(results)
    
    return df, pre_xml_data

# 사용 예시
log_file_path = 'your_log_file.log'
df, pre_data = parse_log_file(log_file_path)

# 결과 확인
print("추출된 XML 데이터:")
print(df.head())

print("\nXML 앞에 있는 데이터 샘플:")
print(pre_data[0] if pre_data else "No pre-XML data found")
```

## 코드 설명

1. **시간 데이터 추출**:
   - 정규식 `\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}`로 타임스탬프 추출
   - 로그 형식에 따라 정규식 수정 가능

2. **XML 블록 처리**:
   - XML 시작 태그(`<...>`)를 발견하면 XML 모드 시작
   - XML 종료 태그(`</...>`)를 발견할 때까지 내용 수집
   - BeautifulSoup으로 XML 유효성 검사

3. **데이터 저장**:
   - 유효한 XML은 딕셔너리로 변환하여 저장
   - 모든 XML 태그와 내용을 개별 컬럼으로 저장
   - 원본 XML과 XML 앞의 데이터도 별도 저장

4. **결과 반환**:
   - 추출된 XML 정보는 pandas DataFrame으로 반환
   - XML 앞의 데이터는 별도 리스트로 반환

## 추가 고려사항

1. 로그 형식에 따라 정규식을 조정해야 할 수 있습니다.
2. 매우 큰 로그 파일의 경우 메모리 효율적인 처리가 필요합니다.
3. XML 네임스페이스가 있는 경우 추가 처리가 필요할 수 있습니다.
4. 여러 XML이 한 줄에 있는 경우 등 예외 상황 처리 추가 가능

이 코드를 실제 로그 형식에 맞게 조정하여 사용하시면 됩니다.